# -*- coding: utf-8 -*-
"""442final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o2kV-v_I_Yqn00NljnF3ATsLwkW2n8VZ

# Setup

Set environment and download dataset images

https://pjreddie.com/projects/pascal-voc-dataset-mirror/

http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html
"""

!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
!tar -xf VOCtrainval_11-May-2012.tar

import os
import time
import json
import random
import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import torchvision
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
from torch.utils.data.dataset import Dataset
from sklearn.metrics import average_precision_score as ap_score
from tqdm import tqdm
import torch.nn.functional as F
import scipy.sparse
from scipy.sparse import lil_matrix as lil_matrix
from torchsummary import summary
from torch import Tensor

if torch.cuda.is_available():
    print("Using the GPU. You are good to go!")
    device = 'cuda'
else:
    print("Using the CPU. Overall speed will be slowed down")
    device = 'cpu'

"""# Dataset"""

class VOCData(Dataset):
    def __init__(self, subset, data_num=500, one_hot=False):
        seg_folder = "VOCdevkit/VOC2012/ImageSets/Segmentation/"   # names of images
        img_folder = "VOCdevkit/VOC2012/JPEGImages/"         # images .jpg
        label_folder = "VOCdevkit/VOC2012/SegmentationClass/"     # groundtruth .png
        self.one_hot=one_hot
        self.dataset = open(seg_folder + subset + '.txt', 'r')
        self.name_list = self.dataset.read().splitlines()

        self.images = [np.array(Image.open(img_folder + img + ".jpg"))
                    for img in self.name_list]
        self.labels = [np.array(Image.open(label_folder + img + ".png"))
                    for img in self.name_list]
        self.transform = transforms.Compose([transforms.Resize((128, 128))])

        self.images = self.images[:data_num]
        self.labels = self.labels[:data_num]

    def __getitem__(self, index):
        image = torch.FloatTensor(self.images[index]).permute(2, 0 ,1) # 3 x X x X 
        image = self.transform(image)
        label = self.labels[index]

        # if 255 in label:
        #   # 1-20 object, 0 background, and 255 void
        #   label[(label != 0) * (label != 255)] = 1
        #   label[label == 255] = 2
        # assert(len(np.unique(label)==3))
        # # 1 object, 0 background, 2 void

        # 0 as background, 1 as object
        if 255 in label:
          label[label == 255] = 0
          label[label != 0] = 1
        assert(len(np.unique(label)) == 2)
        label = torch.LongTensor([self.labels[index]])[None, :, :] # X x X
        label = self.transform(label).squeeze()
        
        if self.one_hot: # for ap calculation
            H, W = label.shape
            label = torch.nn.functional.one_hot(label.reshape(-1), 2).reshape(H, W, -1)
            label = label.permute(2, 0, 1)
            assert torch.max(label) == 1
        return image, label

    def __len__(self):
        return len(self.images)

"""# U-net Model"""

n_classes = 2
bilinear = True
n_channels = 3

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.n_class = 3
        super(Model, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        return x

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        # input is CHW
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)

model = Model().to(device)
summary(model, (3,128,128), device=device)

"""# Helper functions"""

def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):
    # Average of Dice coefficient for all batches, or for a single mask
    assert input.size() == target.size()
    if input.dim() == 2 and reduce_batch_first:
        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')

    if input.dim() == 2 or reduce_batch_first:
        inter = torch.dot(input.reshape(-1), target.reshape(-1))
        sets_sum = torch.sum(input) + torch.sum(target)
        if sets_sum.item() == 0:
            sets_sum = 2 * inter

        return (2 * inter + epsilon) / (sets_sum + epsilon)
    else:
        # compute and average metric for each batch element
        dice = 0
        for i in range(input.shape[0]):
            dice += dice_coeff(input[i, ...], target[i, ...])
        return dice / input.shape[0]


def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):
    # Average of Dice coefficient for all classes
    assert input.size() == target.size()
    dice = 0
    for channel in range(input.shape[1]):
        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)

    return dice / input.shape[1]

def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):
    # Dice loss (objective to minimize) between 0 and 1
    assert input.size() == target.size()
    fn = multiclass_dice_coeff if multiclass else dice_coeff
    return 1 - fn(input, target, reduce_batch_first=True)

def train(trainloader, net, criterion, optimizer, device, epoch):
    grad_scaler = torch.cuda.amp.GradScaler(enabled=False)
    start = time.time()
    running_loss = 0.0
    cnt = 0
    net = net.train()
    for images, labels in tqdm(trainloader):
        images = images.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        output = net(images)
        loss = criterion(output, labels) + dice_loss(F.softmax(output, dim=1).float(),
                                       F.one_hot(labels, net.n_classes).permute(0, 3, 1, 2).float(),
                                       multiclass=True)
        grad_scaler.scale(loss).backward()
        grad_scaler.step(optimizer)
        grad_scaler.update()
        #loss.backward()
        #optimizer.step()
        running_loss += loss.item()
        cnt += 1
    end = time.time()
    running_loss /= cnt
    print('\n [epoch %d] loss: %.3f elapsed time %.3f' %
        (epoch, running_loss, end-start))
    return running_loss

def test(testloader, net, criterion, device):
    losses = 0.
    cnt = 0
    with torch.no_grad():
        net = net.eval()
        for images, labels in tqdm(testloader):
            images = images.to(device)
            labels = labels.to(device)
            output = net(images)
            loss = criterion(output, labels)
            losses += loss.item()
            cnt += 1
    print('\n',losses / cnt)
    return (losses/cnt)

def plot_hist(trn_hist, val_hist):
    x = np.arange(len(trn_hist))
    plt.figure(figsize=(12, 8))
    plt.plot(x, trn_hist)
    plt.plot(x, val_hist)
    plt.legend(['Training', 'Validation'])
    plt.xticks(x)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.savefig('training_hist.png', dpi=300)
    plt.show()

N_CLASS = 2
def cal_AP(testloader, net, criterion, device):
    '''
    Calculate Average Precision
    '''
    losses = 0.
    cnt = 0
    with torch.no_grad():
        net = net.eval()
        preds = [[] for _ in range(N_CLASS)]
        heatmaps = [[] for _ in range(N_CLASS)]
        for images, labels in tqdm(testloader):
            images = images.to(device)
            labels = labels.to(device)
            output = net(images).cpu().numpy()
            for c in range(N_CLASS):
                preds[c].append(output[:, c].reshape(-1))
                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))

        aps = []
        for c in range(N_CLASS):
            preds[c] = np.concatenate(preds[c])
            heatmaps[c] = np.concatenate(heatmaps[c])
            if heatmaps[c].max() == 0:
                ap = float('nan')
            else:
                ap = ap_score(heatmaps[c], preds[c])
                aps.append(ap)
            print("AP = {}".format(ap))
        print("Average Precision (all classes) = {}".format(np.mean(aps)))
        return np.mean(aps)

def predict(net, image):
    net = net.to(device)
    batch = image.unsqueeze(0)
    batch = batch.to(device)
    with torch.no_grad():
        net.eval()
        output = net(batch).cpu().numpy()
    return output

"""# training"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = Model().to(device)
# criterion = nn.CrossEntropyLoss()
# 
# # Define the dataset and dataloder
# train_data = VOCData("train", data_num=1500)
# val_data = VOCData("val", data_num=1500)
# 
# train_loader = DataLoader(train_data, batch_size=32)
# val_loader = DataLoader(val_data, batch_size=32)
# 
# ap_data = VOCData("val", data_num=200, one_hot=True)
# ap_loader = DataLoader(ap_data, batch_size=1)
# 
# learning_rate = 1e-5
# weight_decay = 1e-8
# optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)
# num_epoch = 40
# 
# print('\nStart training')
# trn_hist = []
# val_hist = []
# patience = 10
# curr_count_to_patience = 0
# model.train()
# for epoch in range(num_epoch):
#     print('-----------------Epoch = %d-----------------' % (epoch+1))
#     trn_loss = train(train_loader, model, criterion, optimizer, device, epoch+1)
#     print('Validation loss: ')
#     val_loss = test(val_loader, model, criterion, device)
#     if len(val_hist) > 0 and val_loss > val_hist[np.argmin(val_hist)]:
#       curr_count_to_patience += 1
#     else:
#       curr_count_to_patience = 0
#     trn_hist.append(trn_loss)
#     val_hist.append(val_loss)
#     if curr_count_to_patience >= patience:
#       break
#     plot_hist(trn_hist, val_hist)
# 
#     # save model parameters
#     torch.save(model.state_dict(), str(epoch) + 'model.pkl')
# 
# model.eval()
# cal_AP(ap_loader, model, criterion, device)
# plot_hist(trn_hist, val_hist)

"""# Testing"""

# load model parameters
model_temp = Model().to(device)
model_temp.load_state_dict(torch.load("6model.pkl"))
model_temp = model_temp.cuda()


# save entire model
# torch.save(model, 'model.pth')
# model_temp = torch.load('model.pth')

def print_predict(net, index):
    src = np.array(val_data[index][0], dtype=np.uint8)
    groundtruth = np.array(val_data[index][1])
    # source image
    plt.figure()
    plt.imshow(src.transpose(1,2,0))
    # ground truth
    plt.figure()
    plt.imshow(groundtruth)
    # predicted seg
    src = torch.FloatTensor(src)
    output = predict(net, src).argmax(axis=1).squeeze()
    plt.figure()
    plt.imshow(output.astype(np.uint8))


print_predict(model, 11)
print_predict(model, 16)

"""check matted object """

def check_matting(net, index):
    src = np.array(val_data[index][0], dtype=np.uint8)
    groundtruth = np.array(val_data[index][1])
    # source image
    plt.figure()
    plt.imshow(src.transpose(1,2,0))

    # ground truth
    plt.figure()
    plt.imshow(groundtruth)

    # predicted seg
    src = torch.FloatTensor(src)
    mask = (predict(net, src).argmax(axis=1).squeeze() == 1)
    mat = mask * np.array(src)
    plt.figure()
    plt.imshow(mat.astype(np.uint8).transpose(1,2,0))

check_matting(model, 300)

"""# Matting and Combine"""

def processImg(src, background, dst):
    prediction = predict(model, src)
    print(prediction.shape)
    mask = prediction.argmax(axis=1).squeeze() == 1
    print(mask.shape)
    fgr = src * mask
    bgr = background * (~mask)
    img = fgr + bgr
    img = img.squeeze()
    image = np.array(img, dtype=int)
    image = image.transpose(1, 2, 0)
    # print(image)
    plt.imshow(image)
    cv2.imwrite(dst,np.array(image))
    return mask
    
src = np.array(Image.open("VOCdevkit/VOC2012/JPEGImages/2007_000170.jpg"))
transform = transforms.Compose([transforms.Resize((128, 128))])
src = torch.FloatTensor(src).permute(2, 0 ,1) 
src = transform(src)

background = np.array(Image.open("VOCdevkit/VOC2012/JPEGImages/2007_000121.jpg"))
background = torch.FloatTensor(background).permute(2, 0 ,1) 
background = transform(background)
dst = "./results/result1.jpg"
mask = processImg(src, background, dst)

"""# Possion Editing"""

# reference: https://github.com/willemmanuel/poisson-image-editing/blob/master/poisson.py

def build_lap_mat(N, target_idx):
  idx = target_idx.copy()
  lap_mat = lil_matrix((N, N))
  for i in range(N):
    row = idx[i]
    lap_mat[i, i] = 4
    for point in surround(row):
      in_target = np.where((idx == point).all(axis=1))
      if (len(in_target[0]) != 0):
        lap_mat[i, in_target[0][0]] = -1
  return lap_mat

def is_edge(index, mask):
  if (mask[index[0], index[1]] == False):
    return False
  for point in surround(index):
    if (mask[point[0],point[1]] == False):
      return True
  return False

def surround(row):
  up = np.array([row[0], row[1] + 1])
  down = np.array([row[0], row[1] - 1])
  right = np.array([row[0] + 1, row[1]])
  left = np.array([row[0] - 1, row[1]])
  return np.array([up, down, right, left])

def Possion_combine(mask, target_idx, src, background, lap_mat):
  N = len(target_idx)
  target = np.zeros(N)
  for i in range(N):
    row = target_idx[i]
    a, b = row
    if ((a + 1 >= src.shape[0]) or (a - 1 < 0) 
      or (b + 1 >= src.shape[1]) or (b - 1 < 0)):
      continue
    target[i] = (4 * src[a,b]) - (src[a+1, b]) - (src[a-1, b]) - (src[a, b+1]) - (src[a, b-1])
    if is_edge(row, mask):
      for point in surround(row):
        if mask[point[0],point[1]] == False:
          target[i] += background[point[0], point[1]]
  x = scipy.sparse.linalg.cg(lap_mat, target)
  combination = np.copy(background).astype(int)
  for i in range(N):
    row = target_idx[i]
    combination[row[0],row[1]] = x[0][i]
  return combination

target_idx = np.transpose(np.nonzero(mask))
lap_mat = build_lap_mat(len(target_idx), target_idx)
result_stack = [Possion_combine(mask, target_idx, src[i,:,:], background[i,:,:], lap_mat) for i in range(3)]
result = cv2.merge(result_stack)
plt.imshow(result)